---
tags:
  - reviewer
course: CS2616 - Theory of Automata
period: Finals
assessment: Final Exam
---
# Context Free Grammars

 - more powerful method of describing languages
 - describes features that have a recursive structure
 - first used in the study of human languages
 - **context free languages** - a collection of languages associated with CFGs
 - **pushdown automata** - machines that recognize CFLs

 - A four tuple that consists of
	 - V - a set of variables (uppercase letters)
	 - T - a set of terminals (lowercase alphanumeric characters)
	 - P - a set of production rules that map a variable to (V union T)*
		 - Each production is in the form of `<variable> -> (V union T)*`
	 - S - the start variable (usually starts with S)
 
 - The language of a CFG is the set of all strings over T that can be derived by G
	 - L(G) is the set of strings w belonging in T* such that `S *=> w`
		 - A string w is in L(G) if and only if G can derive w and there is a parse tree whose yield is w
	 - A language M is a context free language if and only if there is a CFG G such that $L(G) = M$
 
 - All regular languages are context-free languages, but not all CFGs are regular
	 - Conversion table from a regular expression to CFG
		 - null set -> no rule
		 - epsilon -> create a production $S \rightarrow \epsilon$
		 - single variable -> create a production $S \rightarrow a$
		 - union of E1 and E2 -> create a production `U -> S1 | S2`
		 - concatenation of E1 and E2 -> create a production `C -> S1S2`
		 - Kleene star of E1 -> create a production `K -> S1K | epsi`

**CFG Derivation**
 - A derivation from A to B is a sequence of zero or more substitutions using the productions of the grammar, beginning with a and ending with B. denoted by $A \Rightarrow B$
 - Sentential Form - The start variable maps to a string A
	 - If `S *=> a`, a is called the sentential form of the grammar
		 - A sentential form that has no variables is called a sentence
	 - A grammar derives a string if `S *=> w`
		 - A grammar derives a string if there a set of derivations from the start state that yields w.
	 - A string w can have different derivations depending on which variable in a sentential form is replaced first
		 - A leftmost derivation is obtained if the leftmost variable is replaced first
		 - A rightmost derivation is obtained if the rightmost variable is replaced first
- Steps in derivation
	- Write down the start variable
	- Find a variable that is written down and a rule that starts with that variable
		- Replace the written down variable with the right side of that rule
	- Repeat step 2 until no variables remain

- **Parse tree**
	- an ordered tree whose nodes are labeled
		- the root is the start variable
		- each leaf is labeled by a terminal or e
		- each internal node is labeled with a variable
		- The concatenation of leaves from left to right is the **yield** of the parse tree
	- Each parse tree corresponds to only one leftmost derivation and only one rightmost derivation
		- Many derivations have the same parse tree
	- A CFG is ambiguous if a string is the yield of more than one parse tree of the grammar
		- We can sometimes find an unambiguous grammar that generates the same language
		- But some cfls can only be generated by (inherently) ambiguous grammars
- **Disambiguation** - converting an ambiguous CFG G to an unambiguous CFG G2 such that they have the same language
	- No algorithm for converting CFGs
	- No algorithm that can tell if a grammar is ambiguous or not
	- Some languages are inherently ambiguous where no unambiguous CFG can exist

# CFG Normal Forms

### Elimination of Useless Symbols
**useless symbol** - a variable or terminal X that does not appear in any sentential form in any derivation of strings in L(G). X cannot be found in derivations from a start variable S to a string of terminals w
 - **Eliminate Symbols not deriving strings in that belong in T***
	 - Loop through each production X->a
		 - if a belongs in T* then add X to Q and all the terminals in a to Q
	 - While there are still variables that can be added to Q
		 - If there is a production X->a such that all variables of a are in Q then add X and all terminals in a to Q
	 - Eliminate all variables, terminals and productions involving symbols not in Q
 - **Eliminate symbols not in sentential forms**
	 - *this step basically runs depth first search from the start node to determine variables that will never be reached*
	 - Mark all variables as unprocessed and let R be a set containing S
	 - While R contains an unprocessed var Y
		 - For each production p that Y maps to
			 - For each variable X on the right side of P
				 - Add X to R if X is not already in R
		 - Mark Y as processed
	 - Eliminate all variables, terminals and productions involving symbols not in R

## Elimination of epsilon productions
 - An e production is a substitution rule of a CFG which has only e on the right hand side
 - A nullable variable is a variable X from which the empty string can be derived
 - If E is in a CFL, it is necessary to derive epsilon but otherwise, e productions can be avoided
	 - they are undesirable since variables can disappear in sentential forms during derivations
	 - and are unproductive since their use in a derivation allows variables to not produce a single terminal of the derived string
		 - makes the yield weird?
 - **Find all nullable variables**
	 - Use an array to keep track of variables that are nullable
	 - Start with a basis that all variables are not nullable except those that map to epsilon
	 - Loop until nothing changes
		 - Iterate through all productions
			 - If a production consists of only variables, and all variables are marked nullable
				 - Mark the left side of the production as nullable
	 - Return the variables marked as nullable
```pseudocode
find_nullable(V, T, P, S)
	// mark all variables as not nullable
	// mark all variables on the left of epsilon productions as nullable
	for var in V
		if P[var] maps to epsilon
			is_null[var] = true
		else
			is_null[var] = false

	while true
		didChange = false;
		for prod in P
			if all the symbols on the right side of P are marked nullable
				is_null[prod.left_side] = true
				didChange = true

		// no more variables can be marked as nullable
		if didChange = false then break;
	
	return SELECT var FROM V WHERE is_null[var]=true;
```
 - **How to remove E-productions**
	 - Find all nullable variables
	 - If the start variable is a nullable variable then create a new start variable `S' -> S | epsi`
	 - For every production, add all combinations of the production where one or more instances of the nullable variables on the right side of -> are replaced by e
		 - If `C -> DD` and D is nullable then `C -> DD | D`
	 - Remove all e-productions except S' -> epsi if it has been added

### Elimination of unit productions
 - A unit production is in the form of `X->Y` where X and Y are some variables of a grammar
 - Strings derivable of Y are also derivable from X
	 - unit productions can be eliminate by making the productions more straightforward

```
eliminate_unit_productions(V, T, P, S)
	g = init_graph()
	for production in P
		if production is a unit production (X, Y)
			if g does not contain X then add X as node
			if g does not contain Y then add Y as node
		add an edge from X to Y

	Detect cycles in the graph // (OMG TARJAN'S STRONGLY CONNECTED COMPONENTS?)
	for cycle in unit_cycle
		if the cycle includes the start variable
			rename all variables in the cycle to the start variable
		else
			rename all variables in the cycle to any one of them
		remove unit productions of the cycle

	Detect unit-production chains between 2 or more variables X_i, X_j
```
 - If E-productions and unit productions must be eliminated, remove e-productions first since removing e-productions can generate unit productions.

### Chomsky Normal Forms
 - all productions follow the form of `X->YZ` or `X->a`
	 - for all variables X, Y, Z and some terminal a
	 - If epsilon is in the language, then `S->e` is allowed but S cannot appear in the right side of any production.
 - Every CFG has a normal form
 - **Conversion Algorithm**
	 - remove useless symbols, e-productions and unit productions
	 - While there is production `X->aZb` where Z is a terminal and a and b belong to T* then replace Z with a new variable Y->Z
		 - *this step basically creates a new variable for every terminal*. `X_a -> a` for every terminal a.
	 - For every production whose right side contains more than 2 variables
		 - Recursively create new productions that contain at most 2 variables.
 - A CNF parse tree of height h has at most 2^(h-1) at level h-1
	 - the length of the yield is at most the number of nodes at level h-1
### Greibach Normal Form
 - all productions follow the form of `X->ab` for some variable X, some terminal a, and a string b of zero or more variables
 - `S->e` is allowed if epsilon is in L(G) but S should not appear in the right side of any production.
# Pushdown Automata

**Comparing PDA/CFG to NFA/Regular Languages**
 - **Languages**: Regular languages -> Context free languages
 - **Syntactic tools**: Regular expressions -> Context free grammars
 - **Computational tools**: NFAs -> Pushdown Automata
	 - A PDA accepts a string W when it can end in some accepting state after consuming all the symbols of w
	 - The language of a PDA is the set of all strings it accepts

**Pushdown automata**
 - A PDA contains everything that an NFA contains, a 7 tuple in the order  $(Q, \sigma, \psi, \delta, q_0, F, \$ )$
	 - Finite set of states (Q)
	 - Input alphabet (Sigma)
	 - Start state (q0)
	 - Set of accepting states (F)
	 - **A transition function**
		 - The transition function maps a triplet of (Current state, current symbol, Top of stack) to a set of new states and stack modifications
		 - Given a current state + current input symbol + current top of stack
			 - It pops the top stack symbol
			 - Pushes a sequence of symbols into the stack
			 - Moves into the next state from a set of states
				 - Since its stronger than NFAs, it can also move into multiple states with the same input symbol
			 - Consumes the input symbol and move to the next symbol
	 - a stack alphabet (trident)
	 - a bottom of stack marker ($) that belongs in the stack alphabet
 - PDA transition diagram
	 - Each transition from 1 state to another is in the form of 
		 - `read X, pop Y, push a`
		 - Otherwise its the same as a NFA diagram
 - **PDA Instantaneous Description (PDA ID)**
	 - A way to illustrate the behavior of a PDA / track what is happening with the stack
	 - Is in the form of `(current state, unread input substring, stack contents)`
	 - A sequence of IDs formed as a result of PDA transitions is called a **PDA computation**
		$$
	\text{(q, str, \$)} \vdash \text{(q', str', new-stack)}
	$$
 - **Acceptance by final states vs by empty stack**
	 - Every NFA is a PDA that accepts by final state since an NFA is a PDA that does not use its stack
	 - Alternative definition of a PDA is acceptance by empty or null stack
		 - A string is accepted if the stack can become empty upon consuming its input. The PDA does not contain final states
		 - The language of a PDA that accepts strings by empty or null stack is
			 - `N(M) = set of strings w such that w is in the language AND there is a PDA computation such that (q0, w, $) can be computed to (any state, epsilon, epsilon)
	 - PDAs that accept by final state are equivalent to PDAs that accept by empty stack
	 - 
**Conversion from Final State to Empty stack (edsed, e, e)**
 - Create a new start state that goes to the existing start state with the transition edsed, $\epsilon, \diamond/\$\diamond$
	 - The bottom of stack marker of the new PDA is diamond, we need to add $ to make it work with the existing PDA
 - From the existing final states, add epsilon transitions to a new state that loops in itself, removing all characters in the stack one at a time

**Conversion from Empty Stack to Final State PDA (edsed, ede, ede)**
 - Create a new start state that goes to the existing start state with the transition edsed, $\epsilon, \diamond/\$\diamond$
	 - The bottom of stack marker of the new PDA is diamond, we need to add $ to make it work with the existing PDA
 - From all states, add ede ($\epsilon, \diamond/\epsilon$) transition to a new final state (marked with double circle)
 
**Conversion from CFG to PDA**
 - Create a PDA from a CFG 4 tuple (Variables, Terminals, Productions, Start Variable)
	 - Set of states q = `{ q0, qloop, qf }`
	 - Final state f = q_f
	 - Input Alphabet sigma = Terminals of the CFG
	 - Stack Alphabet trident = Union of Terminals / Variables / $
 - Create the following transitions in the PDA
	 - Add transition $(q_0, \epsilon, \$) \rightarrow (q_{loop}, S\$)$
		 - first push S into the stack on top of $ and go to the loop state
	 - Add transitions $(q_{loop}, \epsilon, X) \rightarrow (q_{loop}, a)$ for every production $X \rightarrow a \text{ in }P$
		 - allows left side variables of productions to be substituted by the corresponding right sides
		 - these transitions are responsible for "expanding" productions as necessary from the top of the stack, which are consumed by the next set of transitions
	 - Add transitions $(q_{loop}, a, a) \rightarrow (q_{loop}, \epsilon)$
		 - match the next input symbol with the top of the stack, consume the input symbol and pop from the stack if there is a match
		 - these transitions are responsible for consuming input symbols
	 - Add transition $(q_{loop}, \epsilon, \$) \rightarrow (q_f, \epsilon)$
		 - when you've consumed all the productions you generated, go to the accept state

**Conversion from PDA to CFG**
 - from a PDA M, create a CFG 4 tuple
	 - Create a PDA M that accepts by empty stack equivalent to M'
	 - The Terminals of the CFG = Input alphabet of M
	 - The Variables of the CFG
		 - Start state; and 
		 - $[p, X, q]$ for all states p and q, and stack symbol X
			 - Each triplet represents p going to q and consuming X in the stack
 - Add productions $S\rightarrow[q_0, \$, p]$ for every state $p \in Q$
 - Add productions $[p, A, q] \rightarrow a$ whenever $(q, \epsilon) \in \delta(p, a, A)$
	 - look at every edge in the PDA diagram that does not manipulate the stack
 - Add productions $[p, A, p_k] \rightarrow a[q, X_1, p_1] \dots$ whenever $(q, X_1X_2,X_3\dots) \in \delta(p, a, A)$
	 - look at every edge in the PDA diagram, those that manipulate the stack
	 - $p_1, p_2, p_3, \dots, p_k$ are every combination possible
![[Pasted image 20231214183408.png]]
 - **Productions**
$$
\begin{align}
\text{Add start state productions} \\
S \rightarrow [q, $, p] \\
S \rightarrow [q, $, q] \\\\
\text{Add epsilon productions} \\
[q, X, q] \rightarrow 1 \\
[q, \$, q] \rightarrow \epsilon \\\\

\text{Add non-epsilon productions} \\
\text{List of all possible combinations: pp, pq, qp, qq} \\\\

[p, \$, p] \rightarrow 0[p, X, p][p, \$, p] \\
[p, \$, q] \rightarrow 0[p, X, p][p, \$, q] \\
[p, \$, p] \rightarrow 0[p, X, q][q, \$, p] \\
[p, \$, q] \rightarrow 0[p, X, q][q, \$, q] \\\\

[p, X, p] \rightarrow 0[p, X, p][q, X, p] \\
[p, X, q] \rightarrow 0[p, X, p][q, X, q] \\
[p, X, p] \rightarrow 0[p, X, q][q, X, p] \\
[p, X, q] \rightarrow 0[p, X, q][q, X, q] \\\\

[p, \$, p] \rightarrow [q, \$, p] \\
[p, \$, q] \rightarrow [q, \$, q] \\\\

[p, X, p] \rightarrow [q, X, p] \\
[p, X, q] \rightarrow [q, X, q] \\\\

\end{align}
$$
# Properties of Context-Free Languages

**Closure Properties (Union, Concatenation, and Kleene-Star)**
 - CFLs are closed under union $(V_1, T_1, P_1, S_1)$ and $(V_2, T_2, P_2, S_2)$ 
	 - $(V_1 \cup V_2 \cup \{U\}, \text{ } T_1 \cup T_2, \text{ } P_1 \cup P_2 \cup \{U \rightarrow S_1 | S_2\}, \text{ } U)$
	 - There is a new starting variable called U, which maps to $S_1 | S_2$
 - CFLs are closed under concatenation
	 - $(V_1 \cup V_2 \cup \{C\}, \text{ } T_1 \cup T_2, \text{ } P_1 \cup P_2 \cup \{C \rightarrow S_1 \cdot S_2\}, \text{ } C)$
 - CFLs are closed under Kleene-Star
	 - $(V \cup \{K\}, \text{ } T, \text{ } P \cup \{K \rightarrow SK | \epsilon\}, \text{ } K)$
 - CFLs are closed under intersection with regular languages
	 - New CFL
		 - States - cross product of states between PDA and DFA
		 - Accepting states - cross product of accepting states between PDA and DFA
		 - Input alphabet - the intersection of the input alphabet of the PDA and DFA
		 - Starting state - ordered pair of the starting state of DFA and PDA
		 - Stack alphabet - copied from PDA
		 - Bottom of stack marker - copied from PDA
		 - Transition functions
			 - For every epsilon transition $(r, \alpha)\in (p, \epsilon, X)$ in the PDA, and for every q in set of states of the DFA, add $((r, q), \alpha)\in ((p, q), \epsilon, X)$
			 - For every non-epsilon transition $(r, \alpha)\in (p, a, X)$, and for every transition $(q, a) \rightarrow s$ in the DFA that consumes a, add $((r, s), \alpha)\in ((p, q), a, X)$
**Complementation and Intersection**
 - CFLs are not closed under complementation
 - CFLs are not closed under intersection
	 - Simulating two PDAs with one PDA is sometimes impossible
**Decision Algorithms on CFLs**
 - **Finiteness**
	 - Is a context-free language L infinite?
	 - Construct a digraph whose vertices are variables V, for each production, add edges from left side to variables in the right side.
	 - L is finite if the graph has no cycles
 - **Emptiness**
	 - Asks if a CFL is empty
	 - Remove all useless symbols
	 - All symbols that do not derive strings of terminals or are not reachable from the start are eliminated
	 - If the start symbol is eliminated, then the language is empty
 - **Membership**
	 - Is a string w in the context free language L?
	 - **CYK - Cocke-Younger-Kasami Algorithm**
		 - a general algorithm that efficiently answers a membership problem
		 - Create a matrix of size $|V| x |V|$
		 - The rows represent larger and larger substrings from w, with the bottom row starting at substrings of character length, the 1st element of the 1st row represents the entire substring (the string itself)
			 - The matrix is a half-triangular matrix, with the upper right being filled with NULL entries
		 - Start with the last row, and populate the entries with the set of variables that map to the character per column
		 - Next with each proceeding row, split the string in various points and find the sets of those substrings (which is already in the matrix), then take the cross product of the elements in the sets and find the variables that map to the elements of the cross product
		 - Repeat this process until the upper left most entry in the matrix
		 - A string can be derived from L if the start variable S is in the upper left most variable

# Turing Machines
 - FAs and PDAs cannot serve as models for general purpose computers, since some very simple tasks are beyond the capabilities of these models.
	 - First proposed by Alan Turing in 1936
	 - Similar to finite automaton but with an unlimited and unrestricted memory
	 - More accurate model of a general purpose computer
	 - Still cannot solve certain problems, beyond the limits of computation
 - has two parts
	 - Has a two way infinite tape that stores tape symbols, with a read write head that can move left and right
		 - All other tape cells contain a special blank symbol
		 - Tape is divided into cell, and each cell holds one symbol from the tape alphabet.
		 - Tape head can only see one cell at any instant, this cell + the current state determine the next move of the TM
	 - Control area consisting of a finite number of states, a deterministic transition function
		 - based on the current state and symbol under the head
			 - replace the contents of the scanned cell
			 - reposition the tape head left / right cell
			 - transition to some state
		 - The input alphabet is a subset of the tape alphabet. Initially, the tape holds a string of input symbols, starting on the left of the tape
 - A Turing machine is a 7 tuple that contains the following
	 - Q - finite set of states
	 - E - an input alphabet, which is a proper subset of the tape alphabet
	 - Theta - tape alphabet
	 - Delta - transition function
	 - q0 - a start state
	 - qf - an end state
	 - U - blank tape symbol, which belongs in theta but not in E
 - Transition diagrams are written using `<read X> / <write Y>, <move D>`
 - **Instantaneous Description**
	 - Describes the configuration of the TM at any point in time
	 - Shows the symbols on the tape with the current state name inserted before the symbol where the head is on
 - Each input can result in
	 - the accepting state is reached - the TM halts and the input string is accepted
		 - When the string is accepted, additional moves are unnecessary
			 - A string can be accepted even if the entire input is not read
		 - A TM needs only one accepting state
	 - no further moves are possible - the TM is stuck and dies
	 - the TM loops and runs forever without ever reaching the accepting state
		 - A TM does not stop when the head goes beyond the right end of its input
 - The language of a TM is the set of all strings that it accepts, a TM is not allowed to loop forever, it must reach the final state in a finite number of transitions.
## Turing recognizable language
 - **A language accepted by some Turing machine is called a recognizable language**
	 - A TM may not recognize some strings not in its language by looping forever, without actually saying yes or no on these inputs
	 - The Turing-recognizable language is the set of all languages accepted or recognized by some turing machine.
 - **A Turing machine that always halts (never loops) are called deciders / Total Turing Machines**
	 - They always make a decision to accept or reject.
	 - A decided that recognizes some language is said to decide that language.
	 - **A language is decidable (and thus a Turing Decidable Language) if some turing machine decides it.**
		 - All TDLs are TRLs but not the other way around.
 - TDL Theorems.
	 - Every regular language is Turing decidable
	 - Every context free language is Turing-decidable
		 - Construct a Turing machine that accepts the language as a PDA is for the TM to simulate the actions of the PDA.
	 - Some non-context free languages are Turing-decidable
 - TDL and TRL theorems
	 - The complement of a TDL is a TDL
	 - The complement of a non-TDL TRL is not a TRL
	 - the complement of a non-TRL is a non-TRL
 - **Rice Theorem for Decidability**
	 - A property pi of TRLs is a subset of the set of all TRLs
		 - A TRL has this property pi if and only if the TRL is in pi
	 - A trivial property is one of two kinds, the empty set and the set of all TRLs
	 - A non trivial-property includes some TRLs and excludes some TRLs
		 - If pi is a non trivial property of TRLs, then the Language of Pi is undecidable
			 - Examples:
				 - Emptiness
				 - Finiteness
				 - Regularity
				 - Context-freeness
				 - Context-sensitivity
 - Unrecognizability - there exists some language that are not Turing-recognizable
	 - The set of all TMs is countable, the set of all infinite bit strings is uncountable, some languages are not TM-recognizable
# Chomsky Hierarchy
### Type 3: Regular Language
 - A regular grammar is a 4-tuple (V, T, P, S)
	 - V - a finite set of variables / non terminals
	 - T - a finite set of Terminals disjoint with V
	 - P - a set of productions of the form `A->xB` or `A->x` for some variables A and B / and some string x of terminals in T*
	 - S - a start variable that is in V
 - Regular languages are accepted by regular expression
	 - A regular expression is a syntactic model that recursively builds sets of string from primitive regular expressions using union / concatenation and Kleene-Star
		 - They do not gramatically derive strings in the language using productions or substitution rules.
	 - Regular languages are equivalent to finite automata
 - The language of regular grammar is the set of all strings over T that can be derived by G. That is, G accepts the language
	 - Regular grammars can be normalized into right-linear grammars with productions in the form of `A->aB` or `A->epsi`
		 - or left-linear grammars with productions in the form of `A->Ba` or `A->epsi`
 - Right regular grammar to DFA
	 - if you have a production `A->aB` then this is represented by an edge consuming `a` from states A to B
	 - The accepting state is a variable that maps to epsilon
	 - Start from S then use DFS to traverse production rules, and add to the DFA as discovering
 - Right regular grammar to eNFA
	 - If you have a production `A->aB`, then this is represented by an epsilon transition going from `[A]` to `[aB]`
		 - Then make an edge from `[aB]` to `[B]` consuming a.
		 - All variables have e-transitions to where they map to, and if these new states contain terminals, they are consumed before redirecting to other variables
	 - The accepting state is `[epsi]`

### Type 2: Context-Free Languages
 - Has productions in the form of `A->y` where A is some variable and y is a string of variables or terminals

### Type 1: Context-sensitive languages
 - A context sensitive grammar is a 4-tuple (V, T, P, S)
	 - V - a finite set of variables or non-terminals
	 - T - a finite set of terminals disjoint with V
	 - P - a set of productions of the form
		 - `aAb -> aYb`
			 - where A is a variable and `a, y, b` are strings over the variables and terminals
			 - The left side of the production is required to have variables.
		 - `S->epsi` - provided S does not appear on the right side of any production
 - The language of a CSG is the set of all strings over T that can be derived by G
	 - A language is a context-sensitive language if and only if it is the language of some context-sensitive grammar.
 - All context free languages are context-sensitive languages, where the left side does not have a prefix and suffix string
	 - CSLs properly contain the CFLs

## Type 1: Linear Bounded Automaton
 - LBA - a 8-tuple that behaves like a non-deterministic Turing machine
	 - Q - a set of states
	 - Sigma - an input alphabet that is the subset of the tape alphabet
	 - Tape alphabet theta - includes left and right markers to enclose the input
		 - Encloses the input, the head does not move past the end markers and does not write over the end markers
	 - Transition function - (current state, current character) -> set of (next state, replacement, direction)
	 - Start state in Q
	 - End state in Q
	 - Left marker in Theta
	 - Right marker in Theta
 - The language is the set of strings that it accepts. A string in L(M) causes M to reach its final state after a finite number of transitions
 - An LBA is a limited version of Turing machine, and is equivalent with CSGs

### Type 0: Turing Recognizable Languages
 - An **unrestricted grammar** is a 4 tuple (V, T, P, S) where each component is described as follows
	 - V - a finite set of variables or non terminals
	 - T - a finite set disjoint with V
	 - P - a set of productions of the form `lambda -> y` where both sides are strings over the union of V and T
	 - S - a start variable in T
 - TMs are equivalent to unrestricted grammars
 - TDLs properly contain CSLs
# Computability
 - TM as models of computers
	 - A physical random access machine has the ff
		 - A finite number of memory locations
		 - A finite number of registers
		 - A program counter
		 - A finite set of computer instructions
	 - This TM uses three tapes
		 - Input tape that holds the instructions separated by some separator symbol
		 - A configuration tape that holds encodings of instantaneous values of the program counter, registers, memory locations
		 - Work tape that allows the TM to perform intermediate calculations
	 - A turing machine is an idealized computer
	 - Physical computers are gigantic DFAs but with a finite number of states
		 - A more realistic model is the linear bounded automata
 - Church-Turing thesis
	 - The turing machine is an appropriate model of computability
	 - They equate computability with turing-computability, if a function cannot be computed by a Turing machine, it is not effectively computable.
		 - An effective computation may take a long time and a lot of space to complete
		 - Functions that have TMs that eventually terminate and return correct values are effectively computable for those input parameters
	 - Any effectively computable function can be computed by a Turing machine, or any other equivalent model
		 - Turing machines capture the essence of what can be algorithmically computed
 - TM Equivalence with other models
	 - Lambda Calculus - Alonzo Church / Kleene and Rosser
	 - 1-Recursive functions - Kurt Godel and Kleene
	 - Markov Algorithms - Andrey Markov
	 - Post's machine - Emil Post
		 - Strengthened the conjecture that the Turing Machine captures the notion of effective computability in 1936
	 - Combinatorial Logic - Moses Schonfinkel and Haskell Curry
	 - Counter machines, register machines, and random access machines
 - Encoding
	 - An Encoding is a one to one mapping from TMs to strings, usually based on a TM's formal 7-tuple definition
	 - Notated with `<M>`
	 - Strings that are not associated to a valid TM is said to die on an input.
	 - Godel Numbering
		 - an encoding where the associated strings represent numbers
		 - There is an enumeration of all TMs according to the magnitude of Godel Numbers
	 - Universal Turing Machine - a Turing machine that receives an encoding of a turing machine, and a string w
		 - returns if w belongs in the language of the TM
		 - The language of a Universal Turing Machine is called the universal language
		 - The Universal language is recognizable but undecidable (it may never halt)
	 - The halting problem - if there is a turing machine H that given another TM and an input, decides if M halts on W or not
		 - Lh is recognizable but undecidable, there is no total Tm that decides if an arbitrary Tm accepts or rejects an arbitrary w.
 - History
	 - 1670 - Gottfried Wilhelm
		 - A calculating machine - MDAS
		 - A machine that could determine whether mathematical statements are true. (a machine that can solve decision problems). ”Entsheidungsproblem”
	 - 1900 - David Hilbert
		 - Completeness - provably true / false based on A
		 - Any generated set of axioms must bever lead to contradicting statements
			 - Resurfaces the decision problem, since it is asked if a procedure can be devised to generate a set of axioms that are complete and consistent
		 - Diophantin equations
			 - Can a terminating decision algorithm be made, one that finds out if such equations have integer solutions.
	 - 1931 - Kurt Godel
		 - Incompleteness theorems
		 - Proved that any consistent set of axioms for the arithmetic of natural numbers is incomplete
		 - Encoded mathematical statements as natural numbers, allowing him to treat statements as objects themselves.
	 - 1935 - Alonzo Church
		 - Lambda Calculus
			 - A mathematical abstraction for expressing computation based on function abstraction and application
		 - Proved in 1936 that Hilbert's second problem is unsolvable by working on the results of Godel and using lambda calculus
	 - 1945 - John Von Neumann
		 - Von Neumann Architecture is utilized by the computers of today
		 - His design was influenced by the turing machines, which are idealized computers
		 - What computers can compute can also be computed by Turing Machines.
